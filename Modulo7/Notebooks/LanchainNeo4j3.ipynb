{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONf8JtUynjEGQnHWe4WmrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UN-GCPDS/curso_IA_CHEC/blob/main/Modulo7/Notebooks/LanchainNeo4j3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRERIAS"
      ],
      "metadata": {
        "id": "Cuhz25s1bw1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain-community\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "953gUBsIc5E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neo4j\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "GxYDI3andKFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install httpx==0.27.2"
      ],
      "metadata": {
        "id": "Jj0bZEgBOBpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G2Pg9Kva5uJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.graphs import Neo4jGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONEXIÃ“N NEO4J"
      ],
      "metadata": {
        "id": "RFp3qntTb0Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"API-KEY\"\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"URL\",\n",
        "    username=\"USERNAME\",\n",
        "    password=\"PASSWORD\"\n",
        ")\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    ChatOpenAI(temperature=0), graph=graph, verbose=True,allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "d1CNfJkTb3xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a683a8-f5c8-49f7-8f86-29b1d9866b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-52b629513bc9>:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  ChatOpenAI(temperature=0), graph=graph, verbose=True,allow_dangerous_requests=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"\"\"\n",
        "Which fortnite streamer has the most followers?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "TQybeNHYqu9R",
        "outputId": "8422e6f7-a664-4a37-ba03-73355f808b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-7998b9f81cbd>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  chain.run(\"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (s:Stream)-[:PLAYS]->(:Game {name: \"Fortnite\"})\n",
            "RETURN s.name, s.followers\n",
            "ORDER BY s.followers DESC\n",
            "LIMIT 1;\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'s.name': 'thegrefg', 's.followers': 7269018}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thegrefg has 7,269,018 followers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"\"\"\n",
        "Which italian streamer has the most followers?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "BynVpp-Bq2C7",
        "outputId": "a7ed2662-1a50-4671-f8e8-062a3587a665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (s:Stream)-[:HAS_LANGUAGE]->(:Language{name: \"Italian\"})\n",
            "RETURN s.name, s.followers\n",
            "ORDER BY s.followers DESC\n",
            "LIMIT 1\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know the answer.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EJEMPLO QUERY BASICA"
      ],
      "metadata": {
        "id": "zkUj85Vpp92b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "rIO5b9i-rKZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "Task:Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Cypher examples:\n",
        "# How many streamers are from Norway?\n",
        "MATCH (s:Stream)-[:HAS_LANGUAGE]->(:Language {{name: 'no'}})\n",
        "RETURN count(s) AS streamers\n",
        "\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "OSV3-WBjp9gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_language_example = GraphCypherQAChain.from_llm(\n",
        "    ChatOpenAI(temperature=0), graph=graph, verbose=True,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT,allow_dangerous_requests=True\n",
        ")\n",
        "\n",
        "chain_language_example.run(\"\"\"\n",
        "Which Itallian streamer has the most followers?\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "e_G6NGiarM2B",
        "outputId": "ee1c1cbc-14c6-49c4-a37c-3511fea43387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (s:Stream)-[:HAS_LANGUAGE]->(:Language {name: 'it'})\n",
            "RETURN s.name AS streamer, s.followers AS followers\n",
            "ORDER BY followers DESC\n",
            "LIMIT 1\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'streamer': 'pow3rtv', 'followers': 1530428}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pow3rtv has 1,530,428 followers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}